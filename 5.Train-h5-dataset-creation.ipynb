{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"V68dbXr1X3rr"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j3DP_oyWEGu3"},"source":["!apt install rar"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7IB3zDHJsJ7G"},"source":["%matplotlib inline\n","\n","import numpy as np\n","import os\n","import cv2\n","import scipy.ndimage\n","import matplotlib.pyplot as plt\n","\n","from random import seed\n","from random import random\n","from scipy.ndimage import rotate\n","from skimage import measure, morphology\n","from mpl_toolkits.mplot3d.art3d import Poly3DCollection"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IL3XjYqlQ-xc"},"source":["def augment_ct(ct_scan, rot_angle, zoom_factor):\n","\n","  dims = ct_scan.shape\n","  aug_ct_scan = np.zeros((dims))\n","\n","  for i in range(dims[0]):\n","    # Rotation\n","    aug_ct_scan[i] = rotate(ct_scan[i], rot_angle, reshape=False)\n","    # Zoom\n","    aug_ct_scan[i] = cv2_clipped_zoom(aug_ct_scan[i], zoom_factor)\n","\n","  return aug_ct_scan"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cv2_clipped_zoom(img, zoom_factor):\n","    \"\"\"\n","    Center zoom in/out of the given image and returning an enlarged/shrinked view of the image without changing dimensions\n","    Args:\n","        img : image array\n","        zoom_factor : amount of zoom as a ratio (0 to Inf)\n","    \"\"\"\n","    height, width = img.shape[:2] # it's also the final desired shape\n","    new_height, new_width = int(height * zoom_factor), int(width * zoom_factor)\n","\n","    # Crop only the part that will remain in the result (more efficient)\n","    # Centered bbox of the final desired size in resized (larger/smaller) image coordinates\n","    y1, x1 = max(0, new_height - height) // 2, max(0, new_width - width) // 2\n","    y2, x2 = y1 + height, x1 + width\n","    bbox = np.array([y1,x1,y2,x2])\n","    # Map back to original image coordinates\n","    bbox = (bbox / zoom_factor).astype(np.int)\n","    y1, x1, y2, x2 = bbox\n","    cropped_img = img[y1:y2, x1:x2]\n","\n","    # Handle padding when downscaling\n","    resize_height, resize_width = min(new_height, height), min(new_width, width)\n","    pad_height1, pad_width1 = (height - resize_height) // 2, (width - resize_width) // 2\n","    pad_height2, pad_width2 = (height - resize_height) - pad_height1, (width - resize_width) - pad_width1\n","    pad_spec = [(pad_height1, pad_height2), (pad_width1, pad_width2)] + [(0,0)] * (img.ndim - 2)\n","\n","    result = cv2.resize(cropped_img, (resize_width, resize_height))\n","    result = np.pad(result, pad_spec, mode='constant')\n","    assert result.shape[0] == height and result.shape[1] == width\n","\n","    return result"],"metadata":{"id":"eUe2ZMeMPfbu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd ... # <--- INSERT HERE (...) THE PATH OF THE FOLDER"],"metadata":{"id":"Iqr_N9lRPiF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bz0YQxOUEhiG"},"source":["!grep \"\" -c dimentionally-uniform-preprocessed-LUAD-samples.txt # a .txt file containing the list of dimentionally-uniform, preprocessed LUAD scans\n","!grep \"\" -c dimentionally-uniform-preprocessed-LUSC-samples.txt # a .txt file containing the list of dimentionally-uniform, preprocessed LUSC scans\n","\n","!grep \"\" -c train-samples.txt # a .txt file containing the list of training samples\n","!grep \"\" -c val-samples.txt # a .txt file containing the list of validation samples\n","!grep \"\" -c test-samples.txt # a .txt file containing the list of test samples"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ShKQIYG3-AL0","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1FXJpJkFnQRwd36wZrZZ7yd8pdqCZ-2Ts"},"executionInfo":{"status":"ok","timestamp":1660118876064,"user_tz":-120,"elapsed":880180,"user":{"displayName":"AIRTLab DII","userId":"06782619084140121985"}},"outputId":"8d16f59a-a299-41f7-b333-b1c7325fb6c0"},"source":["path_train_list = \"./train-samples.txt\"\n","path_train_file = open(path_train_list, 'r')\n","train_cts = path_train_file.readlines()\n","\n","N_SLICES = 250\n","RES_Y = 190\n","RES_X = 270\n","\n","# Data augmentation\n","N_SAMPLES = len(train_cts)*3\n","\n","ds_train_fp = np.memmap(\"./train-samples-memmap.dat\", mode='w+', shape=(N_SAMPLES, N_SLICES, RES_Y, RES_X))\n","ds_train_lab = np.zeros((N_SAMPLES, 2))\n","\n","i = 0\n","seed(29)\n","print(\"N. of train samples: \",N_SAMPLES)\n","for path in train_cts:\n","  i += 2\n","\n","  path = path.strip()\n","\n","  print(i)\n","  #print(path)\n","\n","  scans = np.load(path)\n","\n","  rand_angle = np.random.uniform(-15,15)\n","  rand_zoom = np.random.uniform(0.8,1.2)\n","  aug_scans = augment_ct(scans, rand_angle, rand_zoom)\n","\n","  ds_train_fp[i-2] = scans\n","  ds_train_fp[i-1] = aug_scans\n","\n","  if \"LUAD\" in path:\n","    print(\"LUAD\")\n","    ds_train_lab[i-2, 0] = 1\n","    ds_train_lab[i-1, 0] = 1\n","  else:\n","    print(\"LUSC\")\n","    ds_train_lab[i-2, 1] = 1\n","    ds_train_lab[i-1, 1] = 1\n","\n","  print(ds_train_lab[i-2])\n","\n","  # Show some slices\n","  plt.imshow(scans[125, :, :], cmap=plt.cm.gray, vmin=0, vmax=80)\n","  plt.show()\n","  plt.imshow(aug_scans[125, :, :], cmap=plt.cm.gray, vmin=0, vmax=80)\n","  plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"YURRCPTbbvAT"},"source":["import h5py\n","\n","ds_train_h5f = h5py.File('./train-zyx-250x190x270.h5', 'w')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gA8hWXtJ3SQX"},"source":["ds_train_h5f.create_dataset('train_X', data=ds_train_fp)\n","ds_train_h5f.create_dataset('train_Y', data=ds_train_lab)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ufKSBlasQX-B"},"source":["ds_train_h5f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4j_NCm1ZDBlw"},"source":["!rar a -m1 -v5g train-zyx-250x190x270.rar \"./train-zyx-250x190x270.h5\""],"execution_count":null,"outputs":[]}]}
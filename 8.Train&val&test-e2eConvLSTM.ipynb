{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"1G5LYxIjfg9uj8FLeYQN2fN7AU0n8KVb0","authorship_tag":"ABX9TyMZpJVoYHVxkccZrTp8YfBN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","metadata":{"id":"MgOTctO0skFo"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x-K1MQTHpmqC"},"source":["!pip install bayesian-optimization\n","!pip install scikit-optimize\n","import h5py\n","import numpy as np\n","import tensorflow as tf\n","import sklearn.metrics as metrics\n","import itertools\n","import matplotlib.pylab as plt\n","import skopt\n","import pandas as pd\n","\n","from tensorflow.keras import layers, models\n","from tensorflow.python.keras import backend as K\n","from tensorflow.python.framework import ops\n","from skopt import gp_minimize\n","from skopt.space import Categorical, Integer\n","from skopt.utils import use_named_args\n","from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n","from itertools import cycle\n","from scipy import interp\n","from mpl_toolkits.axes_grid1 import make_axes_locatable, axes_size"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd ... # <--- INSERT HERE (...) THE PATH OF THE FOLDER"],"metadata":{"id":"OI9kxrp0QI1U"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"smmypCxhw8sL"},"source":["ds_train_h5f = h5py.File(\"./train-zyx-250x190x270.h5\",'r')\n","ds_val_h5f = h5py.File(\"./val-zyx-250x190x270.h5\",'r')\n","ds_test_h5f = h5py.File(\"./test-zyx-250x190x270.h5\",'r')\n","\n","X_train = ds_train_h5f[\"train_X\"]\n","Y_train = ds_train_h5f[\"train_Y\"]\n","\n","X_val = ds_val_h5f[\"val_X\"]\n","Y_val = ds_val_h5f[\"val_Y\"]\n","\n","X_test = ds_test_h5f[\"test_X\"]\n","Y_test = ds_test_h5f[\"test_Y\"]\n","\n","#print(X_train.shape)\n","#print(Y_train.shape)\n","\n","#print(X_val.shape)\n","#print(Y_val.shape)\n","\n","#print(X_test.shape)\n","#print(Y_test.shape)\n","\n","idx_map_train = np.arange(X_train.shape[0])\n","np.random.shuffle(idx_map_train)\n","\n","idx_map_val = np.arange(X_val.shape[0])\n","np.random.shuffle(idx_map_val)\n","\n","idx_map_test = np.arange(X_test.shape[0])\n","np.random.shuffle(idx_map_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_batches_from_train_hdf5_file(hdf5_file, batch_size, idx_map):\n","  file_size = len(hdf5_file['train_Y'])\n","\n","  while 1:\n","    # Count how many entries we have read\n","    n_entries = 0\n","    # As long as we haven't read all entries from the file: keep reading\n","    while n_entries < (file_size - batch_size):\n","      # Start the next batch at index 0\n","      # Create numpy arrays of input data (features)\n","      xs = hdf5_file['train_X'][n_entries: n_entries + batch_size,:,:,:]\n","      xs = np.array(xs)\n","      xs = xs[..., np.newaxis]\n","\n","      ys = hdf5_file['train_Y'][n_entries:n_entries + batch_size]\n","      ys = np.array(ys)\n","\n","      # We have read one more batch from this file\n","      n_entries += batch_size\n","      yield (xs, ys)"],"metadata":{"id":"zghj3XOLTuPR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_batches_from_val_hdf5_file(hdf5_file, batch_size, idx_map):\n","  file_size = len(hdf5_file['val_Y'])\n","\n","  while 1:\n","    # Count how many entries we have read\n","    n_entries = 0\n","    # As long as we haven't read all entries from the file: keep reading\n","    while n_entries < (file_size - batch_size):\n","      # Start the next batch at index 0\n","      # Create numpy arrays of input data (features)\n","      xs = hdf5_file['val_X'][n_entries: n_entries + batch_size,:,:,:]\n","      xs = np.array(xs)\n","      xs = xs[..., np.newaxis]\n","\n","      ys = hdf5_file['val_Y'][n_entries:n_entries + batch_size]\n","      ys = np.array(ys)\n","\n","      # We have read one more batch from this file\n","      n_entries += batch_size\n","      yield (xs, ys)"],"metadata":{"id":"WpW4TzkPUBR_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_batches_from_test_hdf5_file(hdf5_file, batch_size, idx_map):\n","  file_size = len(hdf5_file['test_Y'])\n","\n","  while 1:\n","    # Count how many entries we have read\n","    n_entries = 0\n","    # As long as we haven't read all entries from the file: keep reading\n","    while n_entries < (file_size - batch_size):\n","      # Start the next batch at index 0\n","      # Create numpy arrays of input data (features)\n","      xs = hdf5_file['test_X'][n_entries: n_entries + batch_size,:,:,:]\n","      xs = np.array(xs)\n","      xs = xs[..., np.newaxis]\n","\n","      ys = hdf5_file['test_Y'][n_entries:n_entries + batch_size]\n","      ys = np.array(ys)\n","\n","      # We have read one more batch from this file\n","      n_entries += batch_size\n","      yield (xs, ys)"],"metadata":{"id":"zsoSUfThUOZD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n","  plt.figure(figsize=(6, 6), dpi=80)\n","\n","  im = plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","  plt.title(title)\n","\n","  tick_marks = np.arange(len(classes))\n","  plt.xticks(tick_marks, classes, rotation=45)\n","  plt.yticks(tick_marks, classes)\n","\n","  thresh = cm.max() / 2.\n","  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","    plt.text(j, i, round(cm[i, j],2),\n","      horizontalalignment=\"center\",\n","      color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","  plt.tight_layout()\n","  plt.ylabel('True label')\n","  plt.xlabel('Predicted label')\n","\n","  ax = plt.gca()\n","  divider = make_axes_locatable(ax)\n","  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n","  plt.colorbar(im, cax=cax)"],"metadata":{"id":"O1-9tSxqXbYw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getConvLSTMModel(my_dropout_rate1,\n","                     my_dropout_rate2,\n","                     my_dropout_rate3,\n","                     my_learning_rate,\n","                     my_batch_size,\n","                     verbose=True):\n","\n","  model = models.Sequential()\n","  model.add(layers.ConvLSTM2D(filters=8,\n","                              kernel_size=(3, 3),\n","                              input_shape=(250, 190, 270, 1),\n","                              name=\"convlstm2d_1\"))\n","  model.add(layers.Dropout(my_dropout_rate1,\n","                           name=\"dropout_1\"))\n","  model.add(layers.Flatten(name=\"flatten_1\"))\n","  model.add(layers.Dense(256,\n","                         activation=\"relu\",\n","                         name=\"dense_1\"))\n","  model.add(layers.Dropout(my_dropout_rate2,\n","                           name=\"dropout_2\"))\n","  model.add(layers.Dense(128,\n","                         activation=\"relu\",\n","                         name=\"dense_2\"))\n","  model.add(layers.Dropout(my_dropout_rate3,\n","                           name=\"dropout_3\"))\n","  model.add(layers.Dense(2,\n","                         activation='softmax',\n","                         name=\"dense_3\"))\n","  if verbose:\n","    model.summary()\n","\n","  opt = tf.keras.optimizers.SGD(learning_rate=my_learning_rate)\n","  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n","\n","  return model"],"metadata":{"id":"KqeMUzGFXjGv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dim_dropout1_rate = Categorical([0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], name='my_dropout_rate1')\n","dim_dropout2_rate = Categorical([0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], name='my_dropout_rate2')\n","dim_dropout3_rate = Categorical([0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], name='my_dropout_rate3')\n","dim_learning_rate = Categorical([0.0001, 0.0005, 0.001, 0.005], name='my_learning_rate')\n","dim_batch_size = Integer(low=1, high=5, name=\"my_batch_size\")\n","\n","dimensions = [dim_dropout1_rate,\n","              dim_dropout2_rate,\n","              dim_dropout3_rate,\n","              dim_learning_rate,\n","              dim_batch_size]\n","\n","default_parameters = [0.5, 0.5, 0.5, 0.001, 1]"],"metadata":{"id":"UN4BJ1PoIDX3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@use_named_args(dimensions=dimensions)\n","\n","def fitness(my_dropout_rate1,my_dropout_rate2,my_dropout_rate3,my_learning_rate,my_batch_size):\n","\n","  model = getConvLSTMModel(my_dropout_rate1=my_dropout_rate1,\n","                           my_dropout_rate2=my_dropout_rate2,\n","                           my_dropout_rate3=my_dropout_rate3,\n","                           my_learning_rate=my_learning_rate,\n","                           my_batch_size=my_batch_size)\n","\n","  generator_train = generate_batches_from_train_hdf5_file(ds_train_h5f, 1, idx_map_train)\n","  generator_val = generate_batches_from_val_hdf5_file(ds_val_h5f, 1, idx_map_val)\n","\n","  # Named blackbox because it represents the structure\n","  earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=3, verbose=1, restore_best_weights=True)\n","  callbacks = [earlystop]\n","\n","  blackbox = model.fit(x=generator_train,\n","                      epochs=15,\n","                      batch_size=my_batch_size,\n","                      validation_data=generator_val,\n","                      steps_per_epoch=int(720//my_batch_size),\n","                      callbacks=callbacks,\n","                      validation_steps=int(50//my_batch_size))\n","\n","  # Return the validation accuracy for the last epoch\n","  print(blackbox.history.keys())\n","  accuracy = blackbox.history['val_accuracy'][-1]\n","\n","  # Print the classification accuracy\n","  print()\n","  print(\"Accuracy: {0:.2%}\".format(accuracy))\n","  print()\n","\n","  # Delete the Keras model with these hyper-parameters from memory\n","  del model\n","\n","  # Clear the Keras session, otherwise it will keep adding new models to the same TensorFlow graph each time we create a model with a different set of hyper-parameters\n","  K.clear_session()\n","  ops.reset_default_graph()\n","\n","  return -accuracy"],"metadata":{"id":"fbF3NhEsJa9u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gp_result = gp_minimize(func=fitness,\n","                        dimensions=dimensions,\n","                        noise='gaussian', # set this to a value close to zero (1e-10) if the function is noise-free (default is 'gaussian')\n","                        n_jobs=1, # if n_jobs=-1 number of jobs is set to number of cores (default is 1)\n","                        n_calls=11, # int (default is 100)\n","                        kappa=1.96, # (default is 1.96)\n","                        x0=default_parameters)"],"metadata":{"id":"XmGhXpNnS0OG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"The best accuracy was: \"+str(round(gp_result.fun *-100,2))+\"%\")"],"metadata":{"id":"lqHp0WRdS2wn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gp_result.x"],"metadata":{"id":"DoDakVCoS45B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.concat([pd.DataFrame(gp_result.x_iters, columns = [\"my_dropout_rate1\",\"my_dropout_rate2\",\"my_dropout_rate3\",\"my_learning_rate\",\"my_batch_size\"]),\n","(pd.Series(gp_result.func_vals*-100, name=\"accuracy\"))], axis=1)"],"metadata":{"id":"aVI_Mya0S6Z5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### 1 ###\n","\n","def getConvLSTMModel(verbose=True):\n","\n","  model = models.Sequential()\n","  model.add(layers.ConvLSTM2D(filters=8,\n","                              kernel_size=(3, 3),\n","                              input_shape=(250, 190, 270, 1),\n","                              name=\"convlstm2d_1\"))\n","  model.add(layers.Dropout(0.7,\n","                           name=\"dropout_1\"))\n","  model.add(layers.Flatten(name=\"flatten_1\"))\n","  model.add(layers.Dense(256,\n","                         activation=\"relu\",\n","                         name=\"dense_1\"))\n","  model.add(layers.Dropout(0.3,\n","                           name=\"dropout_2\"))\n","  model.add(layers.Dense(128,\n","                         activation=\"relu\",\n","                         name=\"dense_2\"))\n","  model.add(layers.Dropout(0.3,\n","                           name=\"dropout_3\"))\n","  model.add(layers.Dense(2,\n","                         activation='softmax',\n","                         name=\"dense_3\"))\n","  if verbose:\n","    model.summary()\n","\n","  opt = tf.keras.optimizers.SGD(learning_rate=0.001)\n","  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n","\n","  return model"],"metadata":{"id":"VaQkoFPi7D90"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### 2 ###\n","\n","def getConvLSTMModel(verbose=True):\n","\n","  model = models.Sequential()\n","  model.add(layers.ConvLSTM2D(filters=8,\n","                              kernel_size=(3, 3),\n","                              input_shape=(250, 190, 270, 1),\n","                              name=\"convlstm2d_1\"))\n","  model.add(layers.Dropout(0.5,\n","                           name=\"dropout_1\"))\n","  model.add(layers.Flatten(name=\"flatten_1\"))\n","  model.add(layers.Dense(128,\n","                         activation=\"relu\",\n","                         name=\"dense_1\"))\n","  model.add(layers.Dropout(0.5,\n","                           name=\"dropout_2\"))\n","  model.add(layers.Dense(2,\n","                         activation='softmax',\n","                         name=\"dense_2\"))\n","  if verbose:\n","    model.summary()\n","\n","  opt = tf.keras.optimizers.SGD(learning_rate=0.001)\n","  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n","\n","  return model"],"metadata":{"id":"NadGpXDc2fBz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### 3 ###\n","\n","def getConvLSTMModel(verbose=True):\n","\n","  model = models.Sequential()\n","  model.add(layers.ConvLSTM2D(filters=8,\n","                              kernel_size=(3, 3),\n","                              input_shape=(250, 190, 270, 1),\n","                              name=\"convlstm2d_1\"))\n","  model.add(layers.Dropout(0.7,\n","                           name=\"dropout_1\"))\n","  model.add(layers.Flatten(name=\"flatten_1\"))\n","  model.add(layers.Dense(128,\n","                         activation=\"relu\",\n","                         name=\"dense_1\"))\n","  model.add(layers.Dropout(0.3,\n","                           name=\"dropout_2\"))\n","  model.add(layers.Dense(2,\n","                         activation='softmax',\n","                         name=\"dense_2\"))\n","  if verbose:\n","    model.summary()\n","\n","  opt = tf.keras.optimizers.SGD(learning_rate=0.001)\n","  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n","\n","  return model"],"metadata":{"id":"BCZsqgU2GKoe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = getConvLSTMModel(True)"],"metadata":{"id":"2HNr3zxcnCSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_batch_size = 1\n","my_steps_per_epoch = int(720//my_batch_size)\n","my_validation_steps = int(50//my_batch_size)\n","my_epochs = 50\n","my_callbacks = [\n","                tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5, verbose=1, restore_best_weights=True),\n","                tf.keras.callbacks.ModelCheckpoint(#filepath=\"./model-convlstm-1.h5\",\n","                                                   #filepath=\"./model-convlstm-2.h5\",\n","                                                   #filepath=\"./model-convlstm-3.h5\",\n","                                                   save_best_only=True,\n","                                                   mode='min',\n","                                                   monitor='val_loss'),\n","]\n","\n","generator_train = generate_batches_from_train_hdf5_file(ds_train_h5f, 1, idx_map_train)\n","generator_val = generate_batches_from_val_hdf5_file(ds_val_h5f, 1, idx_map_val)\n","\n","history = model.fit(generator_train, validation_data=generator_val,\n","                    steps_per_epoch=my_steps_per_epoch, validation_steps=my_validation_steps, epochs=my_epochs,\n","                    callbacks=my_callbacks)"],"metadata":{"id":"ywp4zWZq7MZi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### 1 ###\n","\n","classes = ['LUAD','LUSC']\n","my_batch_size = 1\n","my_test_steps = int(60//my_batch_size)\n","\n","generator_test = generate_batches_from_test_hdf5_file(ds_test_h5f, 1, idx_map_test)\n","\n","model_best = tf.keras.models.load_model(\"./model-convlstm-1.h5\")\n","\n","print(\"Evaluation on test data...\")\n","loss, accuracy = model_best.evaluate(X_test, Y_test, steps=my_test_steps)\n","print(\"Loss: \",loss)\n","print(\"Accuracy: \",accuracy)\n","\n","print('Prediction on test data...')\n","probs = model_best.predict(X_test, steps=my_test_steps)\n","print(probs)\n","#np.savetxt(\"./\" + f'prediction-convlstm-1.csv',\n","#            probs,\n","#            delimiter=',',\n","#            fmt='%1.3f',\n","#            header=f'Prediction on NSCLC-Radiomics-Genomics test data:')\n","Y_test = Y_test\n","print(Y_test)\n","#np.savetxt(\"./\" + f'ground-truth-convlstm-1.csv',\n","#            Y_test,\n","#            delimiter=',',\n","#            fmt='%1.3f',\n","#            header=f'Ground truth:')\n","y_pred = np.argmax(probs, axis=1)\n","Y_test = np.argmax(Y_test, axis=1)\n","print(classification_report(Y_test, y_pred, target_names=classes))\n","\n","cnf_matrix = confusion_matrix(Y_test, y_pred)\n","cnf_matrix_norm = (cnf_matrix / cnf_matrix.astype(np.float).sum(axis=1, keepdims=True))*100\n","plot_confusion_matrix(cnf_matrix_norm, classes=classes, title='Confusion matrix')\n","plt.show()\n","\n","preds = probs[:,1]\n","fpr, tpr, threshold = roc_curve(Y_test, preds, pos_label=1)\n","roc_auc = auc(fpr, tpr)\n","plt.plot(fpr, tpr, lw=2, color='b', label = 'AUC = %0.4f' % roc_auc, alpha=.8)\n","plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n","plt.xlim([-0.01, 1.01])\n","plt.ylim([-0.01, 1.01])\n","plt.xlabel('False positive rate (1-specificity)', fontsize=18)\n","plt.ylabel('True positive rate (sensitivity)', fontsize=18)\n","plt.title('ROC', fontsize=18)\n","plt.legend(loc=\"lower right\", prop={'size': 15})\n","plt.show()"],"metadata":{"id":"1apcpj_caKNL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### 2 ###\n","\n","classes = ['LUAD','LUSC']\n","my_batch_size = 1\n","my_test_steps = int(60//my_batch_size)\n","\n","generator_test = generate_batches_from_test_hdf5_file(ds_test_h5f, 1, idx_map_test)\n","\n","model_best = tf.keras.models.load_model(\"./model-convlstm-2.h5\")\n","\n","print(\"Evaluation on test data...\")\n","loss, accuracy = model_best.evaluate(X_test, Y_test, steps=my_test_steps)\n","print(\"Loss: \",loss)\n","print(\"Accuracy: \",accuracy)\n","\n","print('Prediction on test data...')\n","probs = model_best.predict(X_test, steps=my_test_steps)\n","print(probs)\n","#np.savetxt(\"./\" + f'prediction-convlstm-2.csv',\n","#            probs,\n","#            delimiter=',',\n","#            fmt='%1.3f',\n","#            header=f'Prediction on NSCLC-Radiomics-Genomics test data:')\n","Y_test = Y_test\n","print(Y_test)\n","#np.savetxt(\"./\" + f'ground-truth-convlstm-2.csv',\n","#            Y_test,\n","#            delimiter=',',\n","#            fmt='%1.3f',\n","#            header=f'Ground truth:')\n","y_pred = np.argmax(probs, axis=1)\n","Y_test = np.argmax(Y_test, axis=1)\n","print(classification_report(Y_test, y_pred, target_names=classes))\n","\n","cnf_matrix = confusion_matrix(Y_test, y_pred)\n","cnf_matrix_norm = (cnf_matrix / cnf_matrix.astype(np.float).sum(axis=1, keepdims=True))*100\n","plot_confusion_matrix(cnf_matrix_norm, classes=classes, title='Confusion matrix')\n","plt.show()\n","\n","preds = probs[:,1]\n","fpr, tpr, threshold = roc_curve(Y_test, preds, pos_label=1)\n","roc_auc = auc(fpr, tpr)\n","plt.plot(fpr, tpr, lw=2, color='b', label = 'AUC = %0.4f' % roc_auc, alpha=.8)\n","plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n","plt.xlim([-0.01, 1.01])\n","plt.ylim([-0.01, 1.01])\n","plt.xlabel('False positive rate (1-specificity)', fontsize=18)\n","plt.ylabel('True positive rate (sensitivity)', fontsize=18)\n","plt.title('ROC', fontsize=18)\n","plt.legend(loc=\"lower right\", prop={'size': 15})\n","plt.show()"],"metadata":{"id":"7yejBJJU3S7L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### 3 ###\n","\n","classes = ['LUAD','LUSC']\n","my_batch_size = 1\n","my_test_steps = int(60//my_batch_size)\n","\n","generator_test = generate_batches_from_test_hdf5_file(ds_test_h5f, 1, idx_map_test)\n","\n","model_best = tf.keras.models.load_model(\"./model-convlstm-3.h5\")\n","\n","print(\"Evaluation on test data...\")\n","loss, accuracy = model_best.evaluate(X_test, Y_test, steps=my_test_steps)\n","print(\"Loss: \",loss)\n","print(\"Accuracy: \",accuracy)\n","\n","print('Prediction on test data...')\n","probs = model_best.predict(X_test, steps=my_test_steps)\n","print(probs)\n","#np.savetxt(\"./\" + f'prediction-convlstm-3.csv',\n","#            probs,\n","#            delimiter=',',\n","#            fmt='%1.3f',\n","#            header=f'Prediction on NSCLC-Radiomics-Genomics test data:')\n","Y_test = Y_test\n","print(Y_test)\n","#np.savetxt(\"./\" + f'ground-truth-convlstm-3.csv',\n","#            Y_test,\n","#            delimiter=',',\n","#            fmt='%1.3f',\n","#            header=f'Ground truth:')\n","y_pred = np.argmax(probs, axis=1)\n","Y_test = np.argmax(Y_test, axis=1)\n","print(classification_report(Y_test, y_pred, target_names=classes))\n","\n","cnf_matrix = confusion_matrix(Y_test, y_pred)\n","cnf_matrix_norm = (cnf_matrix / cnf_matrix.astype(np.float).sum(axis=1, keepdims=True))*100\n","plot_confusion_matrix(cnf_matrix_norm, classes=classes, title='Confusion matrix')\n","plt.show()\n","\n","preds = probs[:,1]\n","fpr, tpr, threshold = roc_curve(Y_test, preds, pos_label=1)\n","roc_auc = auc(fpr, tpr)\n","plt.plot(fpr, tpr, lw=2, color='b', label = 'AUC = %0.4f' % roc_auc, alpha=.8)\n","plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n","plt.xlim([-0.01, 1.01])\n","plt.ylim([-0.01, 1.01])\n","plt.xlabel('FP rate', fontsize=18)\n","plt.ylabel('TP rate', fontsize=18)\n","plt.title('ROC curve', fontsize=18)\n","plt.legend(loc=\"lower right\", prop={'size': 15})\n","plt.show()"],"metadata":{"id":"1-yuE9NuHFwz"},"execution_count":null,"outputs":[]}]}